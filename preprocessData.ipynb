{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#library to work with vectors and matrix\n",
    "import numpy as np\n",
    "import h5py\n",
    "import cv2\n",
    "import os, inspect\n",
    "\n",
    "#garbage collector\n",
    "import gc\n",
    "#system\n",
    "import sys\n",
    "#work with xml file\n",
    "import xml.etree.cElementTree as ET\n",
    "\n",
    "#plot figures, charts, etc\n",
    "import matplotlib.pyplot as plt \n",
    "\n",
    "from tqdm import tqdm\n",
    "\n",
    "#preprocessing method\n",
    "from preprocessing import rgb_preprocessing, depth_preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def createFileHDF5(pathFile, nameFile):\n",
    "    path = os.path.join(pathFile,nameFile)\n",
    "    #create hdf5 file\n",
    "    file = h5py.File(path, 'w')\n",
    "    #create group training, dev and test\n",
    "    train = file.create_group('train')\n",
    "    #create sub group input and output\n",
    "    _=train.create_group('input')\n",
    "    _=train.create_group('output')\n",
    "        \n",
    "    dev = file.create_group('dev')\n",
    "    #create sub group input and output\n",
    "    _=dev.create_group('input')\n",
    "    _=dev.create_group('output')\n",
    "        \n",
    "    test = file.create_group('test')\n",
    "    #create sub group input and output\n",
    "    _=test.create_group('input')\n",
    "    _=test.create_group('output')\n",
    "        \n",
    "    #close file\n",
    "    #file.close()\n",
    "    return file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loadTag(pathDataInput, pathDataOutput, holdout, windows, shuffle=False):\n",
    "    dataImages = []\n",
    "    if sum(holdout) ==100:\n",
    "        onlyfilesInput = [f for f in os.listdir(pathDataInput) if os.path.isdir(os.path.join(pathDataInput, f))]\n",
    "        onlyfilesOutput = [f for f in os.listdir(pathDataOutput) if os.path.isdir(os.path.join(pathDataOutput, f))]\n",
    "        if windows>=1:\n",
    "            for pathInput, pathOutput in zip(onlyfilesInput,onlyfilesOutput):\n",
    "                inImg = os.listdir(os.path.join(pathDataInput,pathInput))\n",
    "                outImg = os.listdir(os.path.join(pathDataOutput,pathOutput))\n",
    "                zipped = list(zip(inImg,outImg))\n",
    "                np.random.shuffle(zipped)\n",
    "                imgs = [(pathInput+\"/\"+inImg[img], pathOutput+\"/\"+outImg[img]) for img in range(0,len(inImg),windows)]\n",
    "                dataImages.extend(np.squeeze(imgs))\n",
    "        else:\n",
    "            raise Exception('{0} should be more than 1.'.format(windows))\n",
    "    else:\n",
    "        raise Exception('{0} should sum 1.'.format(str(holdout)))\n",
    "    if shuffle:\n",
    "            np.random.shuffle(dataImages)\n",
    "    train = int(np.floor(len(dataImages)*(holdout[0]/100)))\n",
    "    dev = int(np.floor(len(dataImages)*(holdout[1]/100)))\n",
    "    dataImages = np.array(dataImages)\n",
    "    return [dataImages[:train], dataImages[train:train+dev], dataImages[train+dev:]],pathDataInput, pathDataOutput"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def readImgRGB(pathRGB, imgName, shape):\n",
    "    addr = os.path.join(pathRGB, imgName)\n",
    "    img = cv2.imread(addr)\n",
    "    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "    img = rgb_preprocessing(img, shape[0],shape[1])\n",
    "    return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def readImgDepth(pathDepth, imgName, shape):\n",
    "    tree = ET.parse(os.path.join(pathDepth, imgName))\n",
    "    filename, _ = os.path.splitext(imgName.split(\"/\")[1])\n",
    "    elem = tree.find('%s/data' % filename) #busca la etiqueta \"data\" dentro del xml\n",
    "    height= int(tree.find('%s/height' % filename).text) #busca la etiqueta \"alto\" dentro del xml\n",
    "    width= int(tree.find('%s/width' % filename).text) #busca la etiqueta \"ancho\" dentro del xml\n",
    "    strData = elem.text\n",
    "    floatData = list(map(lambda x: np.int16(x), strData.split()))\n",
    "    depthData = np.array(floatData).reshape((height, width))\n",
    "    depthData = depth_preprocessing(depthData,shape[0],shape[1])\n",
    "    return np.array(depthData)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#tags:array => [train, dev, test]\n",
    "def createDataHDF5(filehdf5, tags, inPath, outPath, shapeImg):\n",
    "    for group in filehdf5:\n",
    "        print(\"set up group {0} in h5py file.\".format(group))\n",
    "        for subgroup in filehdf5[group]:\n",
    "            uriHdf5 = filehdf5[\"{0}/{1}\".format(group,subgroup)]\n",
    "            if group == \"train\":\n",
    "                if subgroup == \"input\":\n",
    "                    print(\"=>set up input data from {0}\".format(group))\n",
    "                    dataset = uriHdf5.create_dataset(\"imgs\", (len(tags[0]),)+shapeImg, np.float32)\n",
    "                    for i, train in tqdm(enumerate(tags[0])):\n",
    "                        dataset[i,...] = readImgRGB(inPath, train[0], shapeImg)\n",
    "                if subgroup == \"output\":\n",
    "                    print(\"=>set up output data from {0}\".format(group))\n",
    "                    dataset = uriHdf5.create_dataset(\"imgs\",(len(tags[0]),)+shapeImg, np.float64)\n",
    "                    for i, train in tqdm(enumerate(tags[0])):\n",
    "                        dataset[i,...] = readImgDepth(outPath, train[1], shapeImg)\n",
    "            if group == \"dev\":\n",
    "                if subgroup == \"input\":\n",
    "                    print(\"=>set up input data from {0}\".format(group))\n",
    "                    dataset = uriHdf5.create_dataset(\"imgs\",(len(tags[1]),)+shapeImg, np.float32)\n",
    "                    for i, dev in tqdm(enumerate(tags[1])):\n",
    "                        dataset[i,...] = readImgRGB(inPath, dev[0], shapeImg)\n",
    "                if subgroup == \"output\":\n",
    "                    print(\"=>set up output data from {0}\".format(group))\n",
    "                    dataset = uriHdf5.create_dataset(\"imgs\",(len(tags[1]),)+shapeImg, np.float64)\n",
    "                    for i, dev in tqdm(enumerate(tags[1])):\n",
    "                        dataset[i,...] = readImgDepth(outPath, dev[1], shapeImg)\n",
    "            if group == \"test\":\n",
    "                if subgroup == \"input\":\n",
    "                    print(\"=>set up input data from {0}\".format(group))\n",
    "                    dataset = uriHdf5.create_dataset(\"imgs\",(len(tags[2]),)+shapeImg, np.float32)\n",
    "                    for i, test in tqdm(enumerate(tags[2])):\n",
    "                        dataset[i, ...] = readImgRGB(inPath, test[0], shapeImg)\n",
    "                if subgroup == \"output\":\n",
    "                    print(\"=>set up output data from {0}\".format(group))\n",
    "                    dataset = uriHdf5.create_dataset(\"imgs\",(len(tags[2]),)+shapeImg, np.float64)\n",
    "                    for i, test in tqdm(enumerate(tags[2])):\n",
    "                        dataset[i,...] = readImgDepth(outPath, test[1], shapeImg)\n",
    "    print(\"succesfully completed\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pathFile:String => path where h5py file is created\n",
    "#nameFile:String => name for h5py file\n",
    "#pathDataInput:String => path from our rgb directory (input)\n",
    "#pathDataOutput:String => path from our depth directory (output)\n",
    "#holdout:Int array => how our dataset would be divided [train, dev, test]\n",
    "#windows:Int => skip image in each stream from our dataset (rgb, depth)\n",
    "#shuffle:Bool => if its true then we apply shuffle, otherwise leave this\n",
    "#shapeImg:shape after preprocess => (height,width, chanels)\n",
    "def main(pathFile, nameFile, pathDataInput, pathDataOutput, holdout, windows, shuffle, shapeImg):\n",
    "    filehdf5 = createFileHDF5(pathFile, nameFile)\n",
    "    tags, inPath, outPath = loadTag(pathDataInput, pathDataOutput, holdout, windows, shuffle)\n",
    "    createDataHDF5(filehdf5, tags, inPath, outPath, shapeImg)\n",
    "    filehdf5.close()\n",
    "#currentPath = os.path.dirname(os.path.abspath(inspect.getfile(inspect.currentframe()))) \n",
    "#pathFile = os.path.join(currentPath, \"preprocess data\")\n",
    "#nameFile = \"CGAN.h5\"   \n",
    "#pathDataInput = os.path.join(currentPath, \"dataset/rgb\")\n",
    "#pathDataOutput = os.path.join(currentPath, \"dataset/depth\")\n",
    "#holdout = [80,15,5]\n",
    "#windows = 10\n",
    "#shuffle = True\n",
    "#shapeImg = (224,224,3)\n",
    "#main(pathFile, nameFile, pathDataInput, pathDataOutput, holdout, windows, shuffle, shapeImg)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
